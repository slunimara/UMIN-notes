{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.18.0\n",
      "Keras version: 3.6.0\n"
     ]
    }
   ],
   "source": [
    "# Importujeme si opět knihovny jako minule\n",
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "# https://pypi.org/project/simplemma/\n",
    "import simplemma\n",
    "import pandas as pd\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from transformers import pipeline\n",
    "from transformers import logging\n",
    "\n",
    "# hlásit pouze nejkritičtější chyby\n",
    "logging.set_verbosity(50)\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Keras version: {keras.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2VEc\n",
    "- ukážeme si jak vytvořit embedding space pomocí knihovny [Gensim](https://radimrehurek.com/gensim/models/word2vec.html)\n",
    "- lze to i v Keras – [Embedding layer](https://keras.io/api/layers/core_layers/embedding/)\n",
    "- využijeme dataset [CIIRC-NLP/czech_news_simple-cs](https://huggingface.co/datasets/CIIRC-NLP/czech_news_simple-cs), který obsahuje články z českých novinových stránek mezi lety 2000-2022\n",
    "    - obsahuje 200 záznamů pro každou z 5 kategorií (Zahraniční, Domácí, Sport, Kultura, Ekonomika)\n",
    "    - tento dataset je podmnožina datasetu [hynky/czech_news_dataset_v2](https://huggingface.co/datasets/hynky/czech_news_dataset_v2), který obsahuje přes 1,6 miliónů záznamů"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>headline</th>\n",
       "      <th>brief</th>\n",
       "      <th>keywords</th>\n",
       "      <th>category</th>\n",
       "      <th>content</th>\n",
       "      <th>category_unclean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.irozhlas.cz/ekonomika/citibank-okd...</td>\n",
       "      <td>Soud potvrdil platnost pohledávek Citibank za ...</td>\n",
       "      <td>Pohledávky za více než deset miliard korun, kt...</td>\n",
       "      <td>[Okd, Citibank, Pohledávky, Ostrava, Soud, Poh...</td>\n",
       "      <td>5</td>\n",
       "      <td>V roce 2019 ostravský soud rozhodl, že pohledá...</td>\n",
       "      <td>Ekonomika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.novinky.cz/ekonomika/clanek/lego-c...</td>\n",
       "      <td>Lego chce dát vale plastovým obalům. Pilotní p...</td>\n",
       "      <td>Lego bude balit stavebnice do papíru, nahradí ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>5</td>\n",
       "      <td>Na zavádění nového typu balení a s tím souvise...</td>\n",
       "      <td>Ekonomika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.idnes.cz/ekonomika/domaci/hypoteka...</td>\n",
       "      <td>Hypoteční mejdan končí, úvěry podraží a klesne...</td>\n",
       "      <td>Objem poskytnutých hypoték za letošní rok míří...</td>\n",
       "      <td>[Česká spořitelna, Čnb - česká národní banka, ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Nad touto hranicí byla průměrná úroková sazba ...</td>\n",
       "      <td>Ekonomika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.novinky.cz/ekonomika/clanek/k-milo...</td>\n",
       "      <td>K Milostivému létu se přidaly další banky</td>\n",
       "      <td>Možností, jak se v rámci tzv. Milostivého léta...</td>\n",
       "      <td>[]</td>\n",
       "      <td>5</td>\n",
       "      <td>Milostivé léto je novelou exekučního řádu urče...</td>\n",
       "      <td>Ekonomika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.idnes.cz/zpravy/zahranicni/vakcina...</td>\n",
       "      <td>V evropských zemích se hromadí vakcína AstraZe...</td>\n",
       "      <td>Zemím Evropské unie se ve skladech hromadí nev...</td>\n",
       "      <td>[Francie, Itálie, Španělsko, Německo, Evropská...</td>\n",
       "      <td>1</td>\n",
       "      <td>Například Francie do pátku zužitkovala 16 proc...</td>\n",
       "      <td>Zahraničí</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://www.irozhlas.cz/ekonomika/citibank-okd...   \n",
       "1  https://www.novinky.cz/ekonomika/clanek/lego-c...   \n",
       "2  https://www.idnes.cz/ekonomika/domaci/hypoteka...   \n",
       "3  https://www.novinky.cz/ekonomika/clanek/k-milo...   \n",
       "4  https://www.idnes.cz/zpravy/zahranicni/vakcina...   \n",
       "\n",
       "                                            headline  \\\n",
       "0  Soud potvrdil platnost pohledávek Citibank za ...   \n",
       "1  Lego chce dát vale plastovým obalům. Pilotní p...   \n",
       "2  Hypoteční mejdan končí, úvěry podraží a klesne...   \n",
       "3          K Milostivému létu se přidaly další banky   \n",
       "4  V evropských zemích se hromadí vakcína AstraZe...   \n",
       "\n",
       "                                               brief  \\\n",
       "0  Pohledávky za více než deset miliard korun, kt...   \n",
       "1  Lego bude balit stavebnice do papíru, nahradí ...   \n",
       "2  Objem poskytnutých hypoték za letošní rok míří...   \n",
       "3  Možností, jak se v rámci tzv. Milostivého léta...   \n",
       "4  Zemím Evropské unie se ve skladech hromadí nev...   \n",
       "\n",
       "                                            keywords  category  \\\n",
       "0  [Okd, Citibank, Pohledávky, Ostrava, Soud, Poh...         5   \n",
       "1                                                 []         5   \n",
       "2  [Česká spořitelna, Čnb - česká národní banka, ...         5   \n",
       "3                                                 []         5   \n",
       "4  [Francie, Itálie, Španělsko, Německo, Evropská...         1   \n",
       "\n",
       "                                             content category_unclean  \n",
       "0  V roce 2019 ostravský soud rozhodl, že pohledá...        Ekonomika  \n",
       "1  Na zavádění nového typu balení a s tím souvise...        Ekonomika  \n",
       "2  Nad touto hranicí byla průměrná úroková sazba ...        Ekonomika  \n",
       "3  Milostivé léto je novelou exekučního řádu urče...        Ekonomika  \n",
       "4  Například Francie do pátku zužitkovala 16 proc...        Zahraničí  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(\"hf://datasets/CIIRC-NLP/czech_news_simple-cs/data/test-00000-of-00001-8fd5c2a953da2a24.parquet\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 7 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   url               1000 non-null   object\n",
      " 1   headline          1000 non-null   object\n",
      " 2   brief             1000 non-null   object\n",
      " 3   keywords          1000 non-null   object\n",
      " 4   category          1000 non-null   int64 \n",
      " 5   content           1000 non-null   object\n",
      " 6   category_unclean  1000 non-null   object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 54.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# My se zaměříme pouze na sloupec \"content\", který obsahuje celý text článku\n",
    "df.info()\n",
    "\n",
    "# Předtím něž se podíváte jak jsem udělal preprocessing, popřemýšlejte sami, jak byste jej udělali vy :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['za', 'před', 'pod', 'nad', 'mezi', 'z', 'z', 'do', 'bez', 'kromě',\n",
       "       'krom', 'místo', 'podle', 'podél', 'kolem', 'okolo', 'u', 'vedle',\n",
       "       'během', 'pomocí', 'stran', 'prostřednictvím', 'za', 'vinou',\n",
       "       'naproti', 'proti', 'oproti', 'kvůli', 'díky', 'vůči', 'za',\n",
       "       'před', 'mimo', 'na', 'pode', 'pod', 'nade', 'nad', 'mezi',\n",
       "       'skrze', 'skrz', 'přes', 'o', 'po', 'v', 'na', 'v', 'po', 'při',\n",
       "       'proto', 'a proto', 'tak', 'a tak', 'tudíž', 'a tudíž', 'tedy',\n",
       "       'a', 'i', 'ani', 'nebo', 'či', 'přímo', 'nadto', 'ani–ani',\n",
       "       'jak–tak', 'hned–hned', 'jednak–jednak', 'zčásti–zčásti',\n",
       "       'dílem–dílem', 'a', 'ale', 'avšak', 'však', 'leč', 'nýbrž',\n",
       "       'naopak', 'jenomže', 'jenže', 'sice–ale', 'jistě–ale', 'i', 'ba',\n",
       "       'ba i', 'ba ani', 'nadto', 'dokonce', 'nejen – ale i',\n",
       "       'nejen – nýbrž i', 'nebo', 'aneb', 'buď–nebo', 'buď–anebo',\n",
       "       'totiž', 'vždyť', 'neboť', 'vždyť', 'totiž', 'však', 'také', 'aby',\n",
       "       'jakmile', 'až', 'než', 'nežli', 'zatímco', 'když', 'kdyby',\n",
       "       'pokud', 'protože', 'poněvadž', 'jelikož', 'jestliže', 'přestože',\n",
       "       'ačkoli', 'třebaže', 'i když', 'ač', 'že', 'sotva', 'i když'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pro odstranění předložek a spojek jsem si vytvořil script, který který z wikipedie vyextrahuje všechny předložky a spojky\n",
    "# Cílem je odstranit tyto slova z textu, protože nám nepřináší žádnou informaci navíc\n",
    "# Napadl by někoho lepší způsob? :)\n",
    "combined_words_df = pd.read_csv('prepositions_conjuctions.csv')\n",
    "combined_words_df.head()\n",
    "combined_words_df['word'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null values: 0\n",
      "Number of sentences: 24951\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    [rok, ostravsky, soud, rozhodnout, pohledavka,...\n",
       "1    [tento, rozsudek, se, odvolat, insolvencni, sp...\n",
       "2    [nyni, se, soud, zabyvat, uz, jen, cast, spor,...\n",
       "3    [krajsky, soud, nyni, odpurci, zaloba, insolve...\n",
       "4    [dokazovani, doplneny, znalecke, posudky, dosp...\n",
       "Name: content, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df[\"content\"]\n",
    "\n",
    "# Kontrola, zda neobsahuje nějaké nulové hodnoty\n",
    "print(f\"Number of null values: {data.isnull().sum()}\")\n",
    "\n",
    "# Preprocessing \n",
    "# Primárně využívám regex (pro lepší pochopení doporučuji zkusit https://regex101.com)\n",
    "\n",
    "# Převedení na malá písmena\n",
    "data = data.str.lower()\n",
    "# Odstranění čísel\n",
    "data = data.str.replace(r'\\d+', '', regex=True)\n",
    "# Odstranění předložek a spojek\n",
    "data = data.apply(lambda x: ' '.join(['' if word in combined_words_df['word'].values else word for word in x.split()]))\n",
    "# # Odstranění speciálních znaků (kromě tečky, kterou použijeme pro rozdělení na věty)\n",
    "data = data.str.replace(r'‚|,|(\\?)|!', '', regex=True)\n",
    "# Lemmatizace\n",
    "# tj. převedení slov na základní tvar (např. \"běžel\" -> \"běžet\")\n",
    "data = data.apply(lambda x: ' '.join([simplemma.lemmatize(word, lang='cs') for word in x.split()]))\n",
    "# Odstranění diakritiky\n",
    "data = data.str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
    "# Odstranění nadbytečných mezer\n",
    "data = data.str.replace(r' +', ' ', regex=True)\n",
    "\n",
    "# Titulky rozdělíme na věty\n",
    "sentences = data.str.split('.').explode()\n",
    "# Odstraníme mezery na začátku a na konci, které mohly vzniknout rozdělnením\n",
    "sentences = sentences.str.strip()\n",
    "\n",
    "# Rozdělíme věty na slova\n",
    "word_sentences = sentences.str.split()\n",
    "word_sentences.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(f\"Number of sentences: {len(sentences)}\")\n",
    "word_sentences.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Vytvoření word2vec embeddingu\n",
    "embedding = Word2Vec(sentences=word_sentences.tolist(), vector_size=100, window=5, min_count=2, workers=4)\n",
    "# Parametry:\n",
    "# sentences - data\n",
    "# vector_size - dimenze embeddingu\n",
    "# window - okolí pro kontext\n",
    "# min_count - minimální frekvence slova (pokud je slovo méně časté, tak se ignoruje)\n",
    "# workers - počet jader pro trénování (tj. využíváme paralelizace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Velikost slovníku: 19686\n",
      "['byt', 'se', 'ten', 'ktery', 's', 'on', 'mit', 'rok', 'v', 'k', 'pro', 'ja', 'jeho', 'moci', 'svuj', 'uz', 'od', 'jako', 'tento', 'clovek', 'dalsi', 'jeden', 'co', 'cesky', 'jak', 'vsechen', 'velky', 'hodne', 'uvest', 'muset', 'stat', 'dva', 'jenz', 'jen', 'z', 'novy', 'chtit', 'prvni', 'pak', 'muj', 'procento', 'jeste', 'jit', 'rici', 'zeme', 'kdy', 'doba', 'kde', 'dostat', 'posledni', 'druhy', 'tri', 'jiny', 'napriklad', 'cena', 'vlada', 'spolecnost', 'pripad', 'cely', 'treba', 'situace', 'tam', 'milion', 'dat', 'tym', '-', 'strana', 'zacit', 'nekolik', 'ty', 'mozny', 'rada', 'prave', 'nyni', 'evropsky', 'rikat', 'tady', 'nektery', 'prace', 'zapas', 'firma', 'hrat', 'tyden', 'kazdy', 'coz', 'tisic', ':', 'takovy', 'cast', 'misto', 'hlavni', 'prijit', 'velmi', 'konec', 'asi', 'koruna', 'ted', 'rusky', 'problem', 'mesto']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Velikost slovníku: {len(embedding.wv.key_to_index)}\")\n",
    "# Výpis prvních 100 slov v embeddingu\n",
    "print(list(embedding.wv.key_to_index.keys())[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('uvest', 0.96949303150177),\n",
       " ('mluvci', 0.9641792178153992),\n",
       " ('reditel', 0.9601395726203918),\n",
       " ('diplomacie', 0.9588109254837036),\n",
       " ('ministerstvo', 0.9575371742248535),\n",
       " ('tiskovy', 0.9574517011642456),\n",
       " ('vnitro', 0.9567068219184875),\n",
       " ('dmitrij', 0.9557474255561829),\n",
       " ('zdravotnictvi', 0.9548031687736511),\n",
       " ('statisticky', 0.9547945261001587)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Můžeme získat slova vyskytující se často v okolí slova \"cesky\"\n",
    "# tj. slova, která se často vyskytují v kontextu\n",
    "embedding.wv.most_similar(\"cesky\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.3556578e-01,  6.6056442e-01,  2.9289553e-01,  2.0922945e-01,\n",
       "        1.3379279e-01, -1.1157229e+00,  7.7918214e-01,  1.5907409e+00,\n",
       "       -6.6003579e-01, -6.5995681e-01, -7.7565603e-02, -1.1365488e+00,\n",
       "       -7.9070950e-01,  3.2764357e-01,  1.9667825e-01, -4.3729270e-01,\n",
       "        2.1123627e-01, -9.5436287e-01, -2.3127641e-01, -8.3508027e-01,\n",
       "        3.3504006e-01,  2.5344446e-01,  7.6245689e-01, -8.9429356e-02,\n",
       "       -1.8001343e-01, -1.1773935e-03, -5.7082891e-01, -1.5073353e-01,\n",
       "       -5.1444244e-01,  2.1846554e-01,  1.0024707e+00, -2.0972893e-01,\n",
       "        4.4090363e-01, -6.6870922e-01, -2.3017351e-01,  5.8174312e-01,\n",
       "        2.1814294e-01, -3.3779317e-01, -3.8098174e-01, -7.9261786e-01,\n",
       "        2.9269329e-01, -4.1061288e-01, -5.6123996e-01,  1.8403904e-01,\n",
       "        5.4575789e-01, -4.0096694e-01, -3.6220595e-01,  1.1667681e-01,\n",
       "        6.0313123e-01,  8.8592899e-01,  1.1332589e-01, -3.5279930e-01,\n",
       "       -1.7052186e-01, -6.0629923e-02, -1.6450121e-01,  3.2812136e-01,\n",
       "        9.0128851e-01, -1.7629679e-01, -6.2168139e-01,  3.7017381e-01,\n",
       "        1.4318016e-01, -7.9864778e-02,  1.0578916e-01, -2.2925784e-01,\n",
       "       -8.5687065e-01,  7.1547270e-01, -3.2980649e-03,  7.4581707e-01,\n",
       "       -7.4154770e-01,  8.5870719e-01,  4.4121925e-02,  4.7089249e-01,\n",
       "        1.1461884e+00, -2.4008887e-01,  8.3094698e-01,  4.2493755e-01,\n",
       "       -2.6333737e-01,  8.9785248e-02, -1.6279691e-01,  2.6437655e-01,\n",
       "       -5.8921099e-01, -2.4084310e-01, -1.2475007e-01,  9.3387836e-01,\n",
       "       -6.9195308e-02, -3.9742252e-01,  9.7851818e-03,  5.0783265e-01,\n",
       "        6.6654694e-01,  2.2525682e-01,  9.1989690e-01,  3.0836388e-01,\n",
       "        2.0833488e-01, -1.9043805e-01,  9.6331567e-01,  7.5783348e-01,\n",
       "        6.0173506e-01, -9.6092868e-01,  2.3508845e-01, -3.2478847e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reprezentace slova \"soud\" ve vytvořeném embeddingu\n",
    "embedding.wv['soud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9604165"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Výpočet podobnosti (kosinova vzdalenost / podobnost) mezi slovy\n",
    "embedding.wv.similarity(\"ekonomika\", \"stat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP\n",
    "- ukážeme si jak použít NLP pro různé typy úloh\n",
    "    - nebudeme tedy již vytvářet nový model, ale zaměříme se čistě na použití natrénovaného\n",
    "    - použití natrénovaného modelu na reálných datech se říká inference\n",
    "- doporučuji si projít stránku huggingface, obsahující spostu vytvořených modelů a datasetů (se skvělými filtry pro podrobné hledání)\n",
    "- huggingface nabízí i kurz [NLP Course](https://huggingface.co/learn/nlp-course/chapter0/1) dostupný zdarma\n",
    "    - kurz krásně popisuje jednotlivé témata NLP jak teoreticky tak i prakticky\n",
    "    - navíc krásně funguje v ekosystému celé stránky, kde je možné stahovat natrénované modely i datasety pomocí knihovny [transformers](https://huggingface.co/docs/hub/transformers) a [datasets](https://huggingface.co/docs/hub/datasets-usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.9915289878845215,\n",
       "  'token': 7635,\n",
       "  'token_str': 'rings',\n",
       "  'sequence': 'my favourite movie is the lord of the rings.'},\n",
       " {'score': 0.003682296024635434,\n",
       "  'token': 10029,\n",
       "  'token_str': 'flies',\n",
       "  'sequence': 'my favourite movie is the lord of the flies.'},\n",
       " {'score': 0.0005844107363373041,\n",
       "  'token': 3614,\n",
       "  'token_str': 'ring',\n",
       "  'sequence': 'my favourite movie is the lord of the ring.'},\n",
       " {'score': 0.00044613334466703236,\n",
       "  'token': 6841,\n",
       "  'token_str': 'beast',\n",
       "  'sequence': 'my favourite movie is the lord of the beast.'},\n",
       " {'score': 0.0002883195993490517,\n",
       "  'token': 27754,\n",
       "  'token_str': 'apes',\n",
       "  'sequence': 'my favourite movie is the lord of the apes.'}]"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stáhneme si model bert-base-uncased – https://huggingface.co/google-bert/bert-base-uncased\n",
    "# uncased: nerozlišuje mezi velkými a malými písmeny\n",
    "# base: verze obsahující 110M parametrů\n",
    "# naučen na Anglických datech\n",
    "unmasker_model = pipeline('fill-mask', model='bert-base-uncased')\n",
    "\n",
    "# V následujícím textu se snažíme doplnit slovo na pozici \"[MASK]\"\n",
    "# Model nám vrátí predikce slov, které se na pozici hodí\n",
    "unmasker_model(\"My favourite movie is The Lord of the [MASK].\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'PER',\n",
       "  'score': np.float32(0.99807286),\n",
       "  'word': 'Bilbo Baggins',\n",
       "  'start': np.int32(0),\n",
       "  'end': np.int32(13)},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': np.float32(0.63286144),\n",
       "  'word': 'Ring',\n",
       "  'start': np.int32(53),\n",
       "  'end': np.int32(57)},\n",
       " {'entity_group': 'PER',\n",
       "  'score': np.float32(0.9991155),\n",
       "  'word': 'Frodo',\n",
       "  'start': np.int32(61),\n",
       "  'end': np.int32(66)},\n",
       " {'entity_group': 'PER',\n",
       "  'score': np.float32(0.99817365),\n",
       "  'word': 'Gandalf',\n",
       "  'start': np.int32(78),\n",
       "  'end': np.int32(85)},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': np.float32(0.7092921),\n",
       "  'word': 'Ring of Power',\n",
       "  'start': np.int32(114),\n",
       "  'end': np.int32(127)}]"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Použijeme model distilbert-NER – https://huggingface.co/dslim/distilbert-NER\n",
    "# obsahuje 65.2M parametrů \n",
    "ner = pipeline(\"ner\", model=\"dslim/distilbert-NER\", aggregation_strategy=\"average\")\n",
    "ner(\"Bilbo Baggins celebrates his birthday and leaves the Ring to Frodo, his heir. Gandalf (a wizard) suspects it is a Ring of Power; seventeen years later, he confirms it was lost by the Dark Lord Sauron and counsels Frodo to take it away from the Shire.\")[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.2236422449350357, 'start': 98, 'end': 106, 'answer': 'a wizard'}"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_answerer = pipeline(\"question-answering\")\n",
    "question_answerer(\n",
    "    question=\"Who is Gandalf?\",\n",
    "    context=\"\"\"Gandalf is a protagonist in J. R. R. Tolkien's novels The Hobbit and The Lord of the Rings. He is a wizard, one of the Istari order, and the leader of the Company of the Ring. Tolkien took the name \"Gandalf\" from the Old Norse \"Catalogue of Dwarves\" (Dvergatal) in the Völuspá.\"\"\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
